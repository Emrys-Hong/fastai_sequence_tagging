{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import fire\n",
    "\n",
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "\n",
    "BOS_LABEL = '_bos_'\n",
    "PAD = '_pad_'\n",
    "\n",
    "re1 = re.compile(r'  +')\n",
    "\n",
    "\n",
    "def read_file(filepath):\n",
    "    assert os.path.exists(filepath)\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        sentence = [BOS]\n",
    "        sentence_labels = [BOS_LABEL]\n",
    "        for line in f:\n",
    "            if line == '\\n':\n",
    "                sentences.append(sentence)\n",
    "                labels.append(sentence_labels)\n",
    "                sentence = [BOS]  # use xbos as the start of sentence token\n",
    "                sentence_labels = [BOS_LABEL]\n",
    "            else:\n",
    "                sentence.append(line.split()[0].lower())\n",
    "                # label is generally in the last column\n",
    "                sentence_labels.append(line.split()[-1])\n",
    "        if sentence:  # some files, e.g. NER end on an empty line\n",
    "            sentences.append(sentence)\n",
    "            labels.append(sentence_labels)\n",
    "    return sentences, labels\n",
    "\n",
    "\n",
    "def create_toks(prefix, max_vocab=30000, min_freq=1):\n",
    "    PATH = f'data/nlp_seq/{prefix}/'\n",
    "\n",
    "    names = {}\n",
    "    if prefix == 'ner':\n",
    "        names['train'] = 'train.txt'\n",
    "        names['val'] = 'valid.txt'\n",
    "        names['test'] = 'test.txt'\n",
    "    else:\n",
    "        raise ValueError(f'Filenames for {prefix} have to be added first.')\n",
    "    paths = {}\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        paths[split] = f'{PATH}{names[split]}'\n",
    "\n",
    "    print(f'prefix {prefix} max_vocab {max_vocab} min_freq {min_freq}')\n",
    "\n",
    "    os.makedirs(f'{PATH}tmp', exist_ok=True)\n",
    "    trn_tok, trn_labels = read_file(paths['train'])\n",
    "    val_tok, val_labels = read_file(paths['val'])\n",
    "    test_tok, test_labels = read_file(paths['test'])\n",
    "\n",
    "    for trn_t, trn_l in zip(trn_tok[:5], trn_labels[:5]):\n",
    "        print('Sentence:', trn_t, 'labels:', trn_l)\n",
    "\n",
    "    print(f'# of train: {len(trn_tok)}, # of val: {len(val_tok)},'\n",
    "          f'# of test: {len(test_tok)}')\n",
    "\n",
    "    freq = Counter(p for o in trn_tok for p in o)\n",
    "    print(freq.most_common(25))\n",
    "    itos = [o for o, c in freq.most_common(max_vocab) if c > min_freq]\n",
    "    itos.insert(0, PAD)\n",
    "    itos.insert(0, '_unk_')\n",
    "    stoi = collections.defaultdict(lambda: 0,\n",
    "                                   {v: k for k, v in enumerate(itos)})\n",
    "    print(len(itos))\n",
    "\n",
    "    trn_ids = np.array([[stoi[o] for o in p] for p in trn_tok])\n",
    "    val_ids = np.array([[stoi[o] for o in p] for p in val_tok])\n",
    "    test_ids = np.array([[stoi[o] for o in p] for p in test_tok])\n",
    "\n",
    "    # map the labels to ids\n",
    "    freq = Counter(p for o in trn_labels for p in o)\n",
    "    print(freq)\n",
    "    itol = [l for l, c in freq.most_common()]\n",
    "    itol.insert(1, PAD)  # insert padding label at index 1\n",
    "    print(itol)\n",
    "    ltoi = {l: i for i, l in enumerate(itol)}\n",
    "    trn_lbl_ids = np.array([[ltoi[o] for o in p] for p in trn_labels])\n",
    "    val_lbl_ids = np.array([[ltoi[o] for o in p] for p in val_labels])\n",
    "    test_lbl_ids = np.array([[ltoi[o] for o in p] for p in test_labels])\n",
    "\n",
    "    ids_joined = np.array([[stoi[o] for o in p] for p in trn_tok + val_tok + test_tok])\n",
    "    val_ids_joined = ids_joined[int(len(ids_joined)*0.9):]\n",
    "    ids_joined = ids_joined[:int(len(ids_joined)*0.9)]\n",
    "\n",
    "    np.save(f'{PATH}tmp/trn_ids.npy', trn_ids)\n",
    "    np.save(f'{PATH}tmp/val_ids.npy', val_ids)\n",
    "    np.save(f'{PATH}tmp/test_ids.npy', test_ids)\n",
    "    np.save(f'{PATH}tmp/lbl_trn.npy', trn_lbl_ids)\n",
    "    np.save(f'{PATH}tmp/lbl_val.npy', val_lbl_ids)\n",
    "    np.save(f'{PATH}tmp/lbl_test.npy', test_lbl_ids)\n",
    "    pickle.dump(itos, open(f'{PATH}tmp/itos.pkl', 'wb'))\n",
    "    pickle.dump(itol, open(f'{PATH}tmp/itol.pkl', 'wb'))\n",
    "    np.save(f'{PATH}tmp/trn_lm_ids.npy', ids_joined)\n",
    "    np.save(f'{PATH}tmp/val_lm_ids.npy', val_ids_joined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix ner max_vocab 30000 min_freq 1\n",
      "Sentence: ['xbos', '-docstart-'] labels: ['_bos_', 'O']\n",
      "Sentence: ['xbos', 'eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.'] labels: ['_bos_', 'I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O']\n",
      "Sentence: ['xbos', 'peter', 'blackburn'] labels: ['_bos_', 'I-PER', 'I-PER']\n",
      "Sentence: ['xbos', 'brussels', '1996-08-22'] labels: ['_bos_', 'I-LOC', 'O']\n",
      "Sentence: ['xbos', 'the', 'european', 'commission', 'said', 'on', 'thursday', 'it', 'disagreed', 'with', 'german', 'advice', 'to', 'consumers', 'to', 'shun', 'british', 'lamb', 'until', 'scientists', 'determine', 'whether', 'mad', 'cow', 'disease', 'can', 'be', 'transmitted', 'to', 'sheep', '.'] labels: ['_bos_', 'O', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "# of train: 14988, # of val: 3468,# of test: 3686\n",
      "[('xbos', 14988), ('the', 8390), ('.', 7374), (',', 7290), ('of', 3815), ('in', 3621), ('to', 3424), ('a', 3199), ('and', 2872), ('(', 2861), (')', 2861), ('\"', 2178), ('on', 2092), ('said', 1849), (\"'s\", 1566), ('for', 1465), ('1', 1421), ('-', 1243), ('at', 1146), ('was', 1095), ('2', 973), ('-docstart-', 946), ('0', 945), ('3', 932), ('with', 867)]\n",
      "10953\n",
      "Counter({'O': 170524, '_bos_': 14988, 'I-PER': 11128, 'I-ORG': 10001, 'I-LOC': 8286, 'I-MISC': 4556, 'B-MISC': 37, 'B-ORG': 24, 'B-LOC': 11})\n",
      "['O', '_pad_', '_bos_', 'I-PER', 'I-ORG', 'I-LOC', 'I-MISC', 'B-MISC', 'B-ORG', 'B-LOC']\n"
     ]
    }
   ],
   "source": [
    "create_toks('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% reload_ext autoreload\n",
    "% autoreload 2\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fire\n",
    "from fastai.text import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "# from eval import eval_ner\n",
    "\n",
    "\n",
    "def freeze_all_but(learner, n):\n",
    "    c=learner.get_layer_groups()\n",
    "    for l in c: set_trainable(l, False)\n",
    "    set_trainable(c[n], True)\n",
    "\n",
    "\n",
    "def get_rnn_seq_labeler(bptt, max_seq, n_class, n_tok, emb_sz, n_hid, n_layers, pad_token, layers, drops, bidir=False,\n",
    "                      dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5):\n",
    "    rnn_enc = MultiBatchSeqRNN(bptt, max_seq, n_tok, emb_sz, n_hid, n_layers, pad_token=pad_token, bidir=bidir,\n",
    "                      dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop)\n",
    "    # return SequentialRNN(rnn_enc, LinearBlocks(layers, drops))\n",
    "    return SequentialRNN(rnn_enc, LinearDecoder(n_class, emb_sz, 0.1))\n",
    "\n",
    "\n",
    "class MultiBatchSeqRNN(RNN_Encoder):\n",
    "    def __init__(self, bptt, max_seq, *args, **kwargs):\n",
    "        self.max_seq,self.bptt = max_seq,bptt\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def concat(self, arrs):\n",
    "        return [torch.cat([l[si] for l in arrs]) for si in range(len(arrs[0]))]\n",
    "\n",
    "    def forward(self, input):\n",
    "        sl,bs = input.size()\n",
    "        for l in self.hidden:\n",
    "            for h in l: h.data.zero_()\n",
    "        # raw_outputs, outputs = [],[]\n",
    "        raw_outputs, outputs = super().forward(input)\n",
    "        # for i in range(0, sl, self.bptt):\n",
    "        #     r, o = super().forward(input[i: min(i+self.bptt, sl)])\n",
    "        #     if i>(sl-self.max_seq):\n",
    "        #         raw_outputs.append(r)\n",
    "        #         outputs.append(o)\n",
    "        # return self.concat(raw_outputs), self.concat(outputs)\n",
    "        return raw_outputs, outputs\n",
    "\n",
    "\n",
    "class SeqDataLoader(DataLoader):\n",
    "    def get_batch(self, indices):\n",
    "        res = self.np_collate([self.dataset[i] for i in indices])\n",
    "        # res = self.np_collate([self.dataset[i] for i in indices], self.pad_idx)\n",
    "        # if not self.transpose: return res\n",
    "        # res[0] = res[0].T\n",
    "        # print('First seq:', res[0][0])\n",
    "        # print('First labels:', res[1][0])\n",
    "        res[1] = np.reshape(res[1], -1)  # reshape the labels to one sequence\n",
    "        return res\n",
    "\n",
    "\n",
    "class TextSeqDataset(Dataset):\n",
    "    def __init__(self, x, y, backwards=False, sos=None, eos=None):\n",
    "        self.x,self.y,self.backwards,self.sos,self.eos = x,y,backwards,sos,eos\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]  # we need to get y as array\n",
    "        if self.backwards: x = list(reversed(x))\n",
    "        if self.eos is not None: x = x + [self.eos]\n",
    "        if self.sos is not None: x = [self.sos]+x\n",
    "        return np.array(x),np.array(y)\n",
    "\n",
    "    def __len__(self): return len(self.x)\n",
    "\n",
    "\n",
    "def train_seq(dir_path, cuda_id, lm_id='', clas_id=None, bs=64, cl=1, backwards=False, startat=0, unfreeze=True,\n",
    "              lr=0.01, dropmult=1.0, pretrain=True, bpe=False, use_clr=True,\n",
    "              use_regular_schedule=False, use_discriminative=True, last=False, chain_thaw=False,\n",
    "              from_scratch=False, train_file_id=''):\n",
    "    print(f'prefix {dir_path}; cuda_id {cuda_id}; lm_id {lm_id}; clas_id {clas_id}; bs {bs}; cl {cl}; backwards {backwards}; '\n",
    "        f'dropmult {dropmult} unfreeze {unfreeze} startat {startat}; pretrain {pretrain}; bpe {bpe}; use_clr {use_clr};'\n",
    "        f'use_regular_schedule {use_regular_schedule}; use_discriminative {use_discriminative}; last {last};'\n",
    "        f'chain_thaw {chain_thaw}; from_scratch {from_scratch}; train_file_id {train_file_id}')\n",
    "\n",
    "    if not hasattr(torch._C, '_cuda_setDevice'):\n",
    "        print('CUDA not available. Setting device=-1.')\n",
    "        cuda_id = -1\n",
    "    torch.cuda.set_device(cuda_id)\n",
    "    PRE = 'bwd_' if backwards else 'fwd_'\n",
    "    PRE = 'bpe_' + PRE if bpe else PRE\n",
    "    IDS = 'bpe' if bpe else 'ids'\n",
    "    dir_path = Path(dir_path)\n",
    "    train_file_id = train_file_id if train_file_id == '' else f'_{train_file_id}'\n",
    "    lm_id = lm_id if lm_id == '' else f'{lm_id}_'\n",
    "    clas_id = lm_id if clas_id is None else clas_id\n",
    "    clas_id = clas_id if clas_id == '' else f'{clas_id}_'\n",
    "    lm_file = '/fs-object-detection/paperspace/fastai/courses/coNLL/data/models/lm1_enc' # there is changed by Emrys\n",
    "    \n",
    "    lm_path = dir_path / 'models' / f'{lm_file}.h5'\n",
    "    if not from_scratch:\n",
    "        assert lm_path.exists(), f'Error: {lm_path} does not exist.'\n",
    "    bptt,em_sz,nh,nl = 70,400,1150,3\n",
    "#     bptt, em_sz, nh, nl = 70, 100, 100, 2\n",
    "\n",
    "    opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "\n",
    "    if backwards:\n",
    "        trn_sent = np.load(dir_path / 'tmp' / f'trn_{IDS}{train_file_id}_bwd.npy')\n",
    "        val_sent = np.load(dir_path / 'tmp' / f'val_{IDS}_bwd.npy')\n",
    "        test_sent = np.load(dir_path / 'tmp' / f'test_{IDS}_bwd.npy')\n",
    "    else:\n",
    "        trn_sent = np.load(dir_path / 'tmp' / f'trn_{IDS}{train_file_id}.npy')\n",
    "        val_sent = np.load(dir_path / 'tmp' / f'val_{IDS}.npy')\n",
    "        test_sent = np.load(dir_path / 'tmp' / f'test_{IDS}.npy')\n",
    "\n",
    "    trn_lbls = np.load(dir_path / 'tmp' / f'lbl_trn{train_file_id}.npy')\n",
    "    val_lbls = np.load(dir_path / 'tmp' / f'lbl_val.npy')\n",
    "    test_lbls = np.load(dir_path / 'tmp' / f'lbl_test.npy')\n",
    "    id2label = pickle.load(open(dir_path / 'tmp' / 'itol.pkl', 'rb'))\n",
    "    c = len(id2label)\n",
    "\n",
    "    if bpe:\n",
    "        vs=30002\n",
    "    else:\n",
    "        id2token = pickle.load(open(dir_path / 'tmp' / 'itos.pkl', 'rb'))\n",
    "        vs = len(id2token)\n",
    "\n",
    "    print('Train sentences shape:', trn_sent.shape)\n",
    "    print('Train labels shape:', trn_lbls.shape)\n",
    "    print('Token ids:', [id2token[id_] for id_ in trn_sent[0]])\n",
    "    print('Label ids:', [id2label[id_] for id_ in trn_lbls[0]])\n",
    "\n",
    "    trn_ds = TextSeqDataset(trn_sent, trn_lbls)\n",
    "    val_ds = TextSeqDataset(val_sent, val_lbls)\n",
    "    test_ds = TextSeqDataset(test_sent, test_lbls)\n",
    "    trn_samp = SortishSampler(trn_sent, key=lambda x: len(trn_sent[x]), bs=bs//2)\n",
    "    val_samp = SortSampler(val_sent, key=lambda x: len(val_sent[x]))\n",
    "    test_samp = SortSampler(test_sent, key=lambda x: len(test_sent[x]))\n",
    "    trn_dl = SeqDataLoader(trn_ds, bs//2, transpose=False, num_workers=1, pad_idx=1, sampler=trn_samp)  # TODO why transpose? Should we also transpose the labels?\n",
    "    val_dl = SeqDataLoader(val_ds, bs, transpose=False, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "    test_dl = SeqDataLoader(test_ds, bs, transpose=False, num_workers=1, pad_idx=1, sampler=test_samp)\n",
    "    md = ModelData(dir_path, trn_dl, val_dl, test_dl)\n",
    "\n",
    "    dps = np.array([0.4,0.5,0.05,0.3,0.4])*dropmult\n",
    "    #dps = np.array([0.5, 0.4, 0.04, 0.3, 0.6])*dropmult\n",
    "    #dps = np.array([0.65,0.48,0.039,0.335,0.34])*dropmult\n",
    "    #dps = np.array([0.6,0.5,0.04,0.3,0.4])*dropmult\n",
    "\n",
    "    m = get_rnn_seq_labeler(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "              layers=[em_sz, 50, c], drops=[dps[4], 0.1],\n",
    "              dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])\n",
    "\n",
    "    learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "    learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "    learn.clip=25.\n",
    "    learn.metrics = [accuracy]\n",
    "\n",
    "    lrm = 2.6\n",
    "    if use_discriminative:\n",
    "#         lrs = np.array([lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])\n",
    "        ## Emrys\n",
    "        lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])\n",
    "        ## end\n",
    "    else:\n",
    "        lrs = lr\n",
    "    wd = 1e-6\n",
    "    if not from_scratch:\n",
    "        print(f'Loading encoder from {lm_file}...')\n",
    "        learn.load_encoder(lm_file)\n",
    "    else:\n",
    "        print('Training classifier from scratch. LM encoder is not loaded.')\n",
    "        use_regular_schedule = True\n",
    "\n",
    "    if (startat<1) and pretrain and not last and not chain_thaw and not from_scratch:\n",
    "        learn.freeze_to(-1)\n",
    "        learn.fit(lrs, 1, wds=wd, cycle_len=None if use_regular_schedule else 1,\n",
    "                  use_clr=None if use_regular_schedule or not use_clr else (8,3))\n",
    "        learn.freeze_to(-2)\n",
    "        learn.fit(lrs, 1, wds=wd, cycle_len=None if use_regular_schedule else 1,\n",
    "                  use_clr=None if use_regular_schedule or not use_clr else (8, 3))\n",
    "        learn.save(f'{PRE}{clas_id}clas_0')\n",
    "    elif startat==1:\n",
    "        learn.load(f'{PRE}{clas_id}clas_0')\n",
    "\n",
    "    if chain_thaw:\n",
    "        lrs = np.array([0.0001, 0.0001, 0.0001, 0.001])\n",
    "        ## Emrys\n",
    "        lrm = 2.6\n",
    "        lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])\n",
    "        # end\n",
    "        print('Using chain-thaw. Unfreezing all layers one at a time...')\n",
    "        n_layers = len(learn.get_layer_groups())\n",
    "        print('# of layers:', n_layers)\n",
    "        # fine-tune last layer\n",
    "        learn.freeze_to(-1)\n",
    "        print('Fine-tuning last layer...')\n",
    "        learn.fit(lrs, 1, wds=wd, cycle_len=None if use_regular_schedule else 1,\n",
    "                  use_clr=None if use_regular_schedule or not use_clr else (8,3))\n",
    "        n = 0\n",
    "        # fine-tune all layers up to the second-last one\n",
    "        while n < n_layers-1:\n",
    "            print('Fine-tuning layer #%d.' % n)\n",
    "            freeze_all_but(learn, n)\n",
    "            learn.fit(lrs, 1, wds=wd, cycle_len=None if use_regular_schedule else 1,\n",
    "                      use_clr=None if use_regular_schedule or not use_clr else (8,3))\n",
    "            n += 1\n",
    "\n",
    "    if unfreeze:\n",
    "        learn.unfreeze()\n",
    "    else:\n",
    "        learn.freeze_to(-3)\n",
    "\n",
    "    if last:\n",
    "        print('Fine-tuning only the last layer...')\n",
    "        learn.freeze_to(-1)\n",
    "\n",
    "    if use_regular_schedule:\n",
    "        print('Using regular schedule. Setting use_clr=None, n_cycles=cl, cycle_len=None.')\n",
    "        use_clr = None\n",
    "        n_cycles = cl\n",
    "        cl = None\n",
    "    else:\n",
    "        n_cycles = 1\n",
    "    learn.fit(lrs, n_cycles, wds=wd, cycle_len=cl, use_clr=(8,8) if use_clr else None)\n",
    "    print('Plotting lrs...')\n",
    "    learn.sched.plot_lr()\n",
    "    learn.save(f'{PRE}{clas_id}clas_1')\n",
    "\n",
    "#     eval_ner(learn, id2label, is_test=False)\n",
    "#     eval_ner(learn, id2label, is_test=True)\n",
    "\n",
    "# if __name__ == '__main__': fire.Fire(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix /fs-object-detection/paperspace/fastai/courses/coNLL/data/nlp_seq/ner/; cuda_id 0; lm_id ; clas_id None; bs 64; cl 1; backwards False; dropmult 1.0 unfreeze True startat 0; pretrain True; bpe False; use_clr True;use_regular_schedule False; use_discriminative True; last False;chain_thaw True; from_scratch False; train_file_id \n",
      "Train sentences shape: (14988,)\n",
      "Train labels shape: (14988,)\n",
      "Token ids: ['xbos', '-docstart-']\n",
      "Label ids: ['_bos_', 'O']\n",
      "Loading encoder from /fs-object-detection/paperspace/fastai/courses/coNLL/data/models/lm1_enc...\n",
      "Using chain-thaw. Unfreezing all layers one at a time...\n",
      "# of layers: 5\n",
      "Fine-tuning last layer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7b2ba1d2934015850497e3f589672e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.558872   0.367696   0.896105  \n",
      "\n",
      "Fine-tuning layer #0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72dc0323a1174f85bb25feffb58476e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.708831   0.390806   0.893132  \n",
      "\n",
      "Fine-tuning layer #1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208520de53d2405e9a172cd80db10665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.357456   0.300254   0.914569  \n",
      "\n",
      "Fine-tuning layer #2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bce7b624bd42da95f6e46b63d40bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.288536   0.24484    0.92684   \n",
      "\n",
      "Fine-tuning layer #3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96b20d4347f4838bab8613a430dd7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.248376   0.235873   0.928284  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b16d4d4a0a54610ad731b325d70e310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.219365   0.209649   0.935441  \n",
      "\n",
      "Plotting lrs...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff976a105f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_seq('/fs-object-detection/paperspace/fastai/courses/coNLL/data/nlp_seq/ner/', 0, lm_id='', clas_id=None, bs=64, cl=1, backwards=False, startat=0, unfreeze=True,\n",
    "              lr=0.01, dropmult=1.0, pretrain=True, bpe=False, use_clr=True,\n",
    "              use_regular_schedule=False, use_discriminative=True, last=False, chain_thaw=True,\n",
    "              from_scratch=False, train_file_id='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,j in md.trn_dl.dataset:\n",
    "    if len(i)!=len(j):\n",
    "        print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3648]) torch.Size([3648])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([384]) torch.Size([384])\n",
      "torch.Size([1088]) torch.Size([1088])\n",
      "torch.Size([64]) torch.Size([64])\n",
      "torch.Size([704]) torch.Size([704])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([1056]) torch.Size([1056])\n",
      "torch.Size([544]) torch.Size([544])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([544]) torch.Size([544])\n",
      "torch.Size([512]) torch.Size([512])\n",
      "torch.Size([96]) torch.Size([96])\n",
      "torch.Size([1056]) torch.Size([1056])\n",
      "torch.Size([1024]) torch.Size([1024])\n",
      "torch.Size([576]) torch.Size([576])\n",
      "torch.Size([544]) torch.Size([544])\n",
      "torch.Size([1408]) torch.Size([1408])\n",
      "torch.Size([1312]) torch.Size([1312])\n",
      "torch.Size([576]) torch.Size([576])\n",
      "torch.Size([544]) torch.Size([544])\n",
      "torch.Size([160]) torch.Size([160])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([160]) torch.Size([160])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([512]) torch.Size([512])\n",
      "torch.Size([480]) torch.Size([480])\n",
      "torch.Size([704]) torch.Size([704])\n",
      "torch.Size([672]) torch.Size([672])\n",
      "torch.Size([1056]) torch.Size([1056])\n",
      "torch.Size([1024]) torch.Size([1024])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([384]) torch.Size([384])\n",
      "torch.Size([832]) torch.Size([832])\n",
      "torch.Size([800]) torch.Size([800])\n",
      "torch.Size([544]) torch.Size([544])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([800]) torch.Size([800])\n",
      "torch.Size([800]) torch.Size([800])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([576]) torch.Size([576])\n",
      "torch.Size([544]) torch.Size([544])\n",
      "torch.Size([512]) torch.Size([512])\n",
      "torch.Size([544]) torch.Size([544])\n",
      "torch.Size([1376]) torch.Size([1376])\n",
      "torch.Size([1312]) torch.Size([1312])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([960]) torch.Size([960])\n",
      "torch.Size([928]) torch.Size([928])\n",
      "torch.Size([928]) torch.Size([928])\n",
      "torch.Size([896]) torch.Size([896])\n",
      "torch.Size([640]) torch.Size([640])\n",
      "torch.Size([608]) torch.Size([608])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([1024]) torch.Size([1024])\n",
      "torch.Size([992]) torch.Size([992])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([1184]) torch.Size([1184])\n",
      "torch.Size([1152]) torch.Size([1152])\n",
      "torch.Size([608]) torch.Size([608])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([704]) torch.Size([704])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([416]) torch.Size([416])\n",
      "torch.Size([1344]) torch.Size([1344])\n",
      "torch.Size([1312]) torch.Size([1312])\n",
      "torch.Size([1088]) torch.Size([1088])\n",
      "torch.Size([608]) torch.Size([608])\n",
      "torch.Size([1184]) torch.Size([1184])\n",
      "torch.Size([1120]) torch.Size([1120])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([1056]) torch.Size([1056])\n",
      "torch.Size([1024]) torch.Size([1024])\n",
      "torch.Size([160]) torch.Size([160])\n",
      "torch.Size([512]) torch.Size([512])\n",
      "torch.Size([512]) torch.Size([512])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([1216]) torch.Size([1216])\n",
      "torch.Size([1152]) torch.Size([1152])\n",
      "torch.Size([896]) torch.Size([896])\n",
      "torch.Size([864]) torch.Size([864])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([736]) torch.Size([736])\n",
      "torch.Size([736]) torch.Size([736])\n",
      "torch.Size([512]) torch.Size([512])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([832]) torch.Size([832])\n",
      "torch.Size([896]) torch.Size([896])\n",
      "torch.Size([896]) torch.Size([896])\n",
      "torch.Size([960]) torch.Size([960])\n",
      "torch.Size([960]) torch.Size([960])\n",
      "torch.Size([928]) torch.Size([928])\n",
      "torch.Size([1248]) torch.Size([1248])\n",
      "torch.Size([1216]) torch.Size([1216])\n",
      "torch.Size([704]) torch.Size([704])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([1152]) torch.Size([1152])\n",
      "torch.Size([1088]) torch.Size([1088])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([864]) torch.Size([864])\n",
      "torch.Size([832]) torch.Size([832])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([672]) torch.Size([672])\n",
      "torch.Size([672]) torch.Size([672])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([416]) torch.Size([416])\n",
      "torch.Size([480]) torch.Size([480])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([1024]) torch.Size([1024])\n",
      "torch.Size([960]) torch.Size([960])\n",
      "torch.Size([1056]) torch.Size([1056])\n",
      "torch.Size([1024]) torch.Size([1024])\n",
      "torch.Size([224]) torch.Size([224])\n",
      "torch.Size([480]) torch.Size([480])\n",
      "torch.Size([832]) torch.Size([832])\n",
      "torch.Size([800]) torch.Size([800])\n",
      "torch.Size([1088]) torch.Size([1088])\n",
      "torch.Size([1056]) torch.Size([1056])\n",
      "torch.Size([576]) torch.Size([576])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([1248]) torch.Size([1248])\n",
      "torch.Size([1216]) torch.Size([1216])\n",
      "torch.Size([1120]) torch.Size([1120])\n",
      "torch.Size([832]) torch.Size([832])\n",
      "torch.Size([800]) torch.Size([800])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([224]) torch.Size([224])\n",
      "torch.Size([512]) torch.Size([512])\n",
      "torch.Size([480]) torch.Size([480])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([384]) torch.Size([384])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([704]) torch.Size([704])\n",
      "torch.Size([672]) torch.Size([672])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([736]) torch.Size([736])\n",
      "torch.Size([576]) torch.Size([576])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([224]) torch.Size([224])\n",
      "torch.Size([96]) torch.Size([96])\n",
      "torch.Size([160]) torch.Size([160])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([864]) torch.Size([864])\n",
      "torch.Size([832]) torch.Size([832])\n",
      "torch.Size([224]) torch.Size([224])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([704]) torch.Size([704])\n",
      "torch.Size([672]) torch.Size([672])\n",
      "torch.Size([800]) torch.Size([800])\n",
      "torch.Size([1024]) torch.Size([1024])\n",
      "torch.Size([992]) torch.Size([992])\n",
      "torch.Size([1120]) torch.Size([1120])\n",
      "torch.Size([1088]) torch.Size([1088])\n",
      "torch.Size([576]) torch.Size([576])\n",
      "torch.Size([544]) torch.Size([544])\n",
      "torch.Size([992]) torch.Size([992])\n",
      "torch.Size([928]) torch.Size([928])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([1056]) torch.Size([1056])\n",
      "torch.Size([1024]) torch.Size([1024])\n",
      "torch.Size([416]) torch.Size([416])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([384]) torch.Size([384])\n",
      "torch.Size([864]) torch.Size([864])\n",
      "torch.Size([1280]) torch.Size([1280])\n",
      "torch.Size([1248]) torch.Size([1248])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([1440]) torch.Size([1440])\n",
      "torch.Size([1344]) torch.Size([1344])\n",
      "torch.Size([992]) torch.Size([992])\n",
      "torch.Size([960]) torch.Size([960])\n",
      "torch.Size([1120]) torch.Size([1120])\n",
      "torch.Size([1088]) torch.Size([1088])\n",
      "torch.Size([1120]) torch.Size([1120])\n",
      "torch.Size([1088]) torch.Size([1088])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([1696]) torch.Size([1696])\n",
      "torch.Size([1472]) torch.Size([1472])\n",
      "torch.Size([1184]) torch.Size([1184])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([1344]) torch.Size([1344])\n",
      "torch.Size([1280]) torch.Size([1280])\n",
      "torch.Size([512]) torch.Size([512])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([736]) torch.Size([736])\n",
      "torch.Size([416]) torch.Size([416])\n",
      "torch.Size([416]) torch.Size([416])\n",
      "torch.Size([2528]) torch.Size([2528])\n",
      "torch.Size([1504]) torch.Size([1504])\n",
      "torch.Size([608]) torch.Size([608])\n",
      "torch.Size([480]) torch.Size([480])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([704]) torch.Size([704])\n",
      "torch.Size([704]) torch.Size([704])\n",
      "torch.Size([544]) torch.Size([544])\n",
      "torch.Size([1344]) torch.Size([1344])\n",
      "torch.Size([1280]) torch.Size([1280])\n",
      "torch.Size([160]) torch.Size([160])\n",
      "torch.Size([672]) torch.Size([672])\n",
      "torch.Size([640]) torch.Size([640])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([2016]) torch.Size([2016])\n",
      "torch.Size([1472]) torch.Size([1472])\n",
      "torch.Size([384]) torch.Size([384])\n",
      "torch.Size([384]) torch.Size([384])\n",
      "torch.Size([128]) torch.Size([128])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([672]) torch.Size([672])\n",
      "torch.Size([800]) torch.Size([800])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([1120]) torch.Size([1120])\n",
      "torch.Size([1088]) torch.Size([1088])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([1408]) torch.Size([1408])\n",
      "torch.Size([1344]) torch.Size([1344])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([480]) torch.Size([480])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([736]) torch.Size([736])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([736]) torch.Size([736])\n",
      "torch.Size([480]) torch.Size([480])\n",
      "torch.Size([576]) torch.Size([576])\n",
      "torch.Size([544]) torch.Size([544])\n",
      "torch.Size([1280]) torch.Size([1280])\n",
      "torch.Size([1216]) torch.Size([1216])\n",
      "torch.Size([512]) torch.Size([512])\n",
      "torch.Size([832]) torch.Size([832])\n",
      "torch.Size([800]) torch.Size([800])\n",
      "torch.Size([480]) torch.Size([480])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([416]) torch.Size([416])\n",
      "torch.Size([416]) torch.Size([416])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([608]) torch.Size([608])\n",
      "torch.Size([608]) torch.Size([608])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([1088]) torch.Size([1088])\n",
      "torch.Size([1056]) torch.Size([1056])\n",
      "torch.Size([960]) torch.Size([960])\n",
      "torch.Size([2016]) torch.Size([2016])\n",
      "torch.Size([1408]) torch.Size([1408])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([416]) torch.Size([416])\n",
      "torch.Size([1856]) torch.Size([1856])\n",
      "torch.Size([1440]) torch.Size([1440])\n",
      "torch.Size([480]) torch.Size([480])\n",
      "torch.Size([1248]) torch.Size([1248])\n",
      "torch.Size([1184]) torch.Size([1184])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([896]) torch.Size([896])\n",
      "torch.Size([896]) torch.Size([896])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([1024]) torch.Size([1024])\n",
      "torch.Size([1024]) torch.Size([1024])\n",
      "torch.Size([416]) torch.Size([416])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([1024]) torch.Size([1024])\n",
      "torch.Size([992]) torch.Size([992])\n",
      "torch.Size([832]) torch.Size([832])\n",
      "torch.Size([160]) torch.Size([160])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([160]) torch.Size([160])\n",
      "torch.Size([960]) torch.Size([960])\n",
      "torch.Size([928]) torch.Size([928])\n",
      "torch.Size([992]) torch.Size([992])\n",
      "torch.Size([992]) torch.Size([992])\n",
      "torch.Size([960]) torch.Size([960])\n",
      "torch.Size([512]) torch.Size([512])\n",
      "torch.Size([1056]) torch.Size([1056])\n",
      "torch.Size([992]) torch.Size([992])\n",
      "torch.Size([608]) torch.Size([608])\n",
      "torch.Size([480]) torch.Size([480])\n",
      "torch.Size([480]) torch.Size([480])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([1216]) torch.Size([1216])\n",
      "torch.Size([1184]) torch.Size([1184])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([832]) torch.Size([832])\n",
      "torch.Size([800]) torch.Size([800])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([896]) torch.Size([896])\n",
      "torch.Size([864]) torch.Size([864])\n",
      "torch.Size([1024]) torch.Size([1024])\n",
      "torch.Size([960]) torch.Size([960])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([416]) torch.Size([416])\n",
      "torch.Size([224]) torch.Size([224])\n",
      "torch.Size([224]) torch.Size([224])\n",
      "torch.Size([576]) torch.Size([576])\n",
      "torch.Size([544]) torch.Size([544])\n",
      "torch.Size([608]) torch.Size([608])\n",
      "torch.Size([576]) torch.Size([576])\n",
      "torch.Size([928]) torch.Size([928])\n",
      "torch.Size([896]) torch.Size([896])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([960]) torch.Size([960])\n",
      "torch.Size([928]) torch.Size([928])\n",
      "torch.Size([608]) torch.Size([608])\n",
      "torch.Size([576]) torch.Size([576])\n",
      "torch.Size([544]) torch.Size([544])\n",
      "torch.Size([384]) torch.Size([384])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([1376]) torch.Size([1376])\n",
      "torch.Size([1312]) torch.Size([1312])\n",
      "torch.Size([800]) torch.Size([800])\n",
      "torch.Size([800]) torch.Size([800])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([864]) torch.Size([864])\n",
      "torch.Size([832]) torch.Size([832])\n",
      "torch.Size([832]) torch.Size([832])\n",
      "torch.Size([800]) torch.Size([800])\n",
      "torch.Size([1184]) torch.Size([1184])\n",
      "torch.Size([1120]) torch.Size([1120])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([1920]) torch.Size([1920])\n",
      "torch.Size([1376]) torch.Size([1376])\n",
      "torch.Size([928]) torch.Size([928])\n",
      "torch.Size([896]) torch.Size([896])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([224]) torch.Size([224])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([672]) torch.Size([672])\n",
      "torch.Size([672]) torch.Size([672])\n",
      "torch.Size([608]) torch.Size([608])\n",
      "torch.Size([576]) torch.Size([576])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([736]) torch.Size([736])\n",
      "torch.Size([704]) torch.Size([704])\n",
      "torch.Size([224]) torch.Size([224])\n",
      "torch.Size([928]) torch.Size([928])\n",
      "torch.Size([1376]) torch.Size([1376])\n",
      "torch.Size([1280]) torch.Size([1280])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([1024]) torch.Size([1024])\n",
      "torch.Size([992]) torch.Size([992])\n",
      "torch.Size([1280]) torch.Size([1280])\n",
      "torch.Size([1216]) torch.Size([1216])\n",
      "torch.Size([736]) torch.Size([736])\n",
      "torch.Size([704]) torch.Size([704])\n",
      "torch.Size([384]) torch.Size([384])\n",
      "torch.Size([992]) torch.Size([992])\n",
      "torch.Size([960]) torch.Size([960])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800]) torch.Size([800])\n",
      "torch.Size([672]) torch.Size([672])\n",
      "torch.Size([416]) torch.Size([416])\n",
      "torch.Size([384]) torch.Size([384])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([96]) torch.Size([96])\n",
      "torch.Size([160]) torch.Size([160])\n",
      "torch.Size([1088]) torch.Size([1088])\n",
      "torch.Size([1056]) torch.Size([1056])\n",
      "torch.Size([160]) torch.Size([160])\n",
      "torch.Size([1792]) torch.Size([1792])\n",
      "torch.Size([1312]) torch.Size([1312])\n",
      "torch.Size([864]) torch.Size([864])\n",
      "torch.Size([2176]) torch.Size([2176])\n",
      "torch.Size([1440]) torch.Size([1440])\n",
      "torch.Size([384]) torch.Size([384])\n",
      "torch.Size([352]) torch.Size([352])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([1152]) torch.Size([1152])\n",
      "torch.Size([1120]) torch.Size([1120])\n",
      "torch.Size([640]) torch.Size([640])\n",
      "torch.Size([608]) torch.Size([608])\n",
      "torch.Size([384]) torch.Size([384])\n",
      "torch.Size([384]) torch.Size([384])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([1312]) torch.Size([1312])\n",
      "torch.Size([1216]) torch.Size([1216])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([288]) torch.Size([288])\n",
      "torch.Size([896]) torch.Size([896])\n",
      "torch.Size([864]) torch.Size([864])\n",
      "torch.Size([224]) torch.Size([224])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([192]) torch.Size([192])\n",
      "torch.Size([160]) torch.Size([160])\n",
      "torch.Size([96]) torch.Size([96])\n",
      "torch.Size([1184]) torch.Size([1184])\n",
      "torch.Size([1120]) torch.Size([1120])\n",
      "torch.Size([832]) torch.Size([832])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([1184]) torch.Size([1184])\n",
      "torch.Size([1888]) torch.Size([1888])\n",
      "torch.Size([1472]) torch.Size([1472])\n",
      "torch.Size([416]) torch.Size([416])\n",
      "torch.Size([384]) torch.Size([384])\n",
      "torch.Size([928]) torch.Size([928])\n",
      "torch.Size([928]) torch.Size([928])\n",
      "torch.Size([640]) torch.Size([640])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([1184]) torch.Size([1184])\n",
      "torch.Size([1088]) torch.Size([1088])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([320]) torch.Size([320])\n",
      "torch.Size([864]) torch.Size([864])\n",
      "torch.Size([832]) torch.Size([832])\n",
      "torch.Size([512]) torch.Size([512])\n",
      "torch.Size([480]) torch.Size([480])\n",
      "torch.Size([256]) torch.Size([256])\n",
      "torch.Size([64]) torch.Size([64])\n",
      "torch.Size([1024]) torch.Size([1024])\n",
      "torch.Size([992]) torch.Size([992])\n",
      "torch.Size([704]) torch.Size([704])\n",
      "torch.Size([128]) torch.Size([128])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([448]) torch.Size([448])\n",
      "torch.Size([704]) torch.Size([704])\n",
      "torch.Size([252]) torch.Size([252])\n"
     ]
    }
   ],
   "source": [
    "for i,j in iter(md.trn_dl):\n",
    "    print(i.view(-1).size(), j.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?? DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1,2,3,4).size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
